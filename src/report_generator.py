"""
Report Generator â€” turns benchmark CSVs into polished Markdown tables
suitable for pasting directly into the README.
"""

import argparse
import pandas as pd
from pathlib import Path


LATENCY_COLORS = {  # thresholds in ms for emoji badges
    "fast": 10,
    "ok": 50,
}


def latency_badge(ms: float) -> str:
    if ms < LATENCY_COLORS["fast"]:
        return "ðŸŸ¢"
    elif ms < LATENCY_COLORS["ok"]:
        return "ðŸŸ¡"
    return "ðŸ”´"


def generate_latency_table(df: pd.DataFrame) -> str:
    """One row per (model, backend), batch_size=1 only for the main table."""
    subset = df[df["batch_size"] == 1].copy()
    subset["badge"] = subset["mean_latency_ms"].apply(latency_badge)
    subset["Latency (ms)"] = subset.apply(
        lambda r: f"{r['badge']} {r['mean_latency_ms']:.1f}", axis=1
    )
    subset["p95 (ms)"] = subset["p95_latency_ms"].round(1)
    subset["Throughput (s/s)"] = subset["throughput_samples_per_sec"].round(1)
    subset["Size (MB)"] = subset["model_size_mb"].apply(
        lambda x: f"{x:.1f}" if pd.notna(x) else "â€”"
    )

    table = subset[["model_name", "backend", "Latency (ms)", "p95 (ms)", "Throughput (s/s)", "Size (MB)"]]
    table = table.rename(columns={"model_name": "Model", "backend": "Backend"})
    table = table.sort_values(["Model", "Backend"])

    return table.to_markdown(index=False)


def generate_batch_scaling_table(df: pd.DataFrame, model: str) -> str:
    """Latency vs batch size for a specific model."""
    subset = df[df["model_name"] == model].copy()
    pivot = subset.pivot_table(
        index="batch_size",
        columns="backend",
        values="mean_latency_ms",
    ).round(2)
    pivot.index.name = "Batch Size"
    return pivot.to_markdown()


def generate_report(results_dir: str) -> str:
    csv_path = Path(results_dir) / "benchmark_results.csv"
    df = pd.read_csv(csv_path)

    models = df["model_name"].unique()

    lines = [
        "# ðŸ“Š Benchmark Results",
        "",
        "> Auto-generated by `src/report_generator.py`. Do not edit manually.",
        "",
        "## Legend",
        "ðŸŸ¢ < 10ms &nbsp;&nbsp; ðŸŸ¡ 10â€“50ms &nbsp;&nbsp; ðŸ”´ > 50ms",
        "",
        "## Latency & Throughput (batch_size=1)",
        "",
        generate_latency_table(df),
        "",
        "## Batch Scaling",
        "",
    ]

    for model in models:
        lines += [
            f"### {model}",
            "",
            generate_batch_scaling_table(df, model),
            "",
        ]

    return "\n".join(lines)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--results-dir", default="results")
    parser.add_argument("--output", default="RESULTS.md")
    args = parser.parse_args()

    report = generate_report(args.results_dir)
    Path(args.output).write_text(report)
    print(f"Report written to {args.output}")