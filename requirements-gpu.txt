torch>=2.6.0
torchvision>=0.21.0
onnx>=1.16.0
onnxruntime-gpu>=1.18.0          # use onnxruntime-gpu for CUDA
transformers>=4.40.0
huggingface-hub>=0.23.0
numpy>=1.26.0
pandas>=2.2.0
tabulate>=0.9.0              # for .to_markdown()
optimum[onnxruntime-gpu]>=1.20.0 # optional: HF-native ONNX export